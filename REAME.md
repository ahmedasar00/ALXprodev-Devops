# Advanced Shell Scripting Project

A collection of shell scripts demonstrating various automation and data processing techniques using the Pokémon API. This project covers API automation, data extraction, batch processing, and report generation.

## Overview

This project consists of five main scripts that work together to fetch, process, and analyze Pokémon data from the [PokéAPI](https://pokeapi.co/). Each script demonstrates different shell scripting concepts and best practices.

## Prerequisites

- Bash shell (version 4.0 or higher)
- `curl` - for making HTTP requests
- `jq` - for JSON parsing and manipulation
- `awk` - for text processing and calculations
- `sed` - for text transformations

### Installation

On Ubuntu/Debian:

```bash
sudo apt-get update
sudo apt-get install curl jq gawk sed
```

On macOS:

```bash
brew install curl jq gawk gnu-sed
```

## Project Structure

```
Advanced_shell/
├── apiAutomation-0x00              # API request automation script
├── data_extraction_automation-0x01 # Data extraction and formatting script
├── batchProcessing-0x02            # Sequential batch processing script
├── summaryData-0x03                # CSV report generation script
├── batchProcessing-0x04            # Parallel batch processing script
├── data.json                       # Output: Pikachu data from API
├── errors.txt                      # Error log file
├── pokemon_data/                   # Directory containing fetched Pokémon JSON files
│   ├── bulbasaur.json
│   ├── ivysaur.json
│   ├── venusaur.json
│   ├── charmander.json
│   └── charmeleon.json
└── pokemon_report.csv              # Generated CSV report
```

## Scripts Description

### 1. `apiAutomation-0x00`

**Purpose:** Automates API requests to fetch Pikachu data from the PokéAPI.

**Features:**

- Makes HTTP GET request to the PokéAPI
- Handles network errors and HTTP status codes
- Saves successful responses to `data.json`
- Logs errors to `errors.txt` with timestamps
- Proper error handling for both network and HTTP errors

**Usage:**

```bash
chmod +x apiAutomation-0x00
./apiAutomation-0x00
```

**Output:**

- `data.json` - Contains the JSON response for Pikachu
- `errors.txt` - Contains error logs if the request fails

---

### 2. `data_extraction_automation-0x01`

**Purpose:** Extracts and formats data from the JSON file generated by the API automation script.

**Features:**

- Extracts Pokémon name, type, height, and weight from JSON
- Converts height from decimeters to meters
- Converts weight from hectograms to kilograms
- Formats output with proper capitalization
- Uses `jq`, `sed`, and `awk` for data processing

**Usage:**

```bash
chmod +x data_extraction_automation-0x01
./data_extraction_automation-0x01
```

**Prerequisites:** Requires `data.json` file (generated by `apiAutomation-0x00`)

**Output Example:**

```
Pikachu is of type Electric, weighs 6kg, and is 0.4m tall.

```

---

### 3. `batchProcessing-0x02`

**Purpose:** Sequentially fetches data for multiple Pokémon with retry logic.

**Features:**

- Fetches data for multiple Pokémon (bulbasaur, ivysaur, venusaur, charmander, charmeleon)
- Implements retry mechanism (up to 3 attempts per Pokémon)
- Adds delays between requests to be API-friendly
- Creates output directory automatically
- Handles failures gracefully

**Usage:**

```bash
chmod +x batchProcessing-0x02
./batchProcessing-0x02
```

**Output:**

- Creates `pokemon_data/` directory
- Saves individual JSON files for each Pokémon

---

### 4. `summaryData-0x03`

**Purpose:** Generates a CSV report from multiple Pokémon JSON files with statistics.

**Features:**

- Processes all JSON files in the current directory
- Extracts name, height, and weight for each Pokémon
- Converts units (decimeters to meters, hectograms to kilograms)
- Generates CSV report with headers
- Calculates and displays average height and weight

**Usage:**

```bash
chmod +x summaryData-0x03
cd pokemon_data  # Run from directory containing JSON files
../summaryData-0x03
```

**Output:**

- `pokemon_report.csv` - CSV file with Pokémon data
- Console output showing averages

**CSV Format:**

```csv
Name,Height (m),Weight (kg)
Pikachu,0.4,6
...
```

---

### 5. `batchProcessing-0x04`

**Purpose:** Fetches data for multiple Pokémon in parallel using background processes.

**Features:**

- Parallel processing using background jobs
- Process ID (PID) tracking
- Job control demonstration
- Faster execution compared to sequential processing
- Waits for all processes to complete

**Usage:**

```bash
chmod +x batchProcessing-0x04
./batchProcessing-0x04
```

**Output:**

- Creates/updates `pokemon_data/` directory
- Saves individual JSON files for each Pokémon
- Shows background job status

**Note:** This script demonstrates parallel processing concepts and is faster than the sequential version (`batchProcessing-0x02`).

---

## Workflow Example

Here's a typical workflow to run all scripts in sequence:

```bash
# Step 1: Fetch Pikachu data via API
./apiAutomation-0x00

# Step 2: Extract and display formatted data
./data_extraction_automation-0x01

# Step 3: Fetch multiple Pokémon data (sequential)
./batchProcessing-0x02

# Step 4: Generate CSV report from fetched data
cd pokemon_data
../summaryData-0x03
cd ..

# Step 5: (Alternative) Fetch multiple Pokémon data in parallel
./batchProcessing-0x04
```

## Error Handling

- All scripts include proper error handling
- Network errors are caught and logged
- HTTP errors (4xx, 5xx) are handled appropriately
- Scripts exit with appropriate status codes
- Error messages are descriptive and include timestamps where applicable

## Best Practices Demonstrated

- ✅ Proper shebang usage (`#!/bin/bash` or `#!/usr/bin/env bash`)
- ✅ Error handling and exit codes
- ✅ Input validation
- ✅ Logging and error reporting
- ✅ Retry mechanisms
- ✅ Rate limiting (delays between requests)
- ✅ Parallel processing
- ✅ Process management
- ✅ Data transformation and formatting
- ✅ CSV generation
- ✅ JSON parsing with `jq`
- ✅ Text processing with `awk` and `sed`

## Notes

- The scripts are designed to work with the PokéAPI, which is a free public API
- Rate limiting is implemented to be respectful to the API
- All scripts are executable and can be run independently
- The project demonstrates both sequential and parallel processing approaches
